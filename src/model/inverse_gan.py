""" model to inverse the gan generator to encode a image to the latent space """

"""
This code is largely inspired by 
https://github.com/simoroma/RecoverGANlatentVector/blob/master/recover_latent_vector.py

Given an image (possibly generated by the GAN)
this scripts tries to recover its latent vector.

The algorithm is based on the ICLR 17 workshop paper:
https://openreview.net/forum?id=HJC88BzFl
Precise Recovery of Latent Vectors from Generative Adversarial Networks
by Zachary C. Lipton, and Subarna Tripathi

It requires:
- a starting image, ./interpolation_from_start/foo_00.png
- its latent vector (optional) ./interpolation_from_start/zp_start.npy
"""


import numpy as np
import tensorflow as tf
from PIL import Image
import pickle

import src.tf_gan.generate_image as generate_image

#

shape_img = (3, 1024, 1024)

def infer_z_from_x(Gs, x):
    target_x = tf.Variable(np.random.normal(size=(1,512)), dtype=tf.float32)
    layer_z = tf.Variable(np.random.normal(0, 1, (1, )+ shape_img,), tf.float32)
    dummy = tf.constant(np.zeros((1, 0)), tf.float32)
    # layer_x = Gs.run()



##


##
yn_old_Code = False
if yn_old_Code:
    import numpy as np
    import tensorflow as tf
    from PIL import Image

    pathfile_img = './asset_resutls/pggan_celeb'

    folder = "./interpolation_from_start/"
    # Choose a random starting point
    zp = tf.Variable(np.random.normal(size=(1,512)), dtype=tf.float32)
    # Or if we know the original latent vector, we can start from it
    start_zp = np.load(folder + "zp_start.npy")
    # zzp = np.empty((1,512))
    # zzp[0] = start_zp
    # zp = tf.Variable(zzp, dtype=tf.float32)

    # Load the image for which we want to recover the latent vector
    # and crete an appropriate tensor for it
    start_img = Image.open(folder + "foo_00.png")
    start_img.resize((128, 128), Image.ANTIALIAS)
    start_img_np = np.array(start_img)/255
    fz = tf.Variable(start_img_np, tf.float32)
    fz = tf.expand_dims(fz, 0)
    fz = tf.cast(fz,tf.float32)

    # Define the optimization problem
    generator = hub.Module("https://tfhub.dev/google/progan-128/1")
    fzp = generator(zp)
    loss = tf.losses.mean_squared_error(labels=fz, predictions=fzp)

    # Decayed gradient descent
    global_step = tf.Variable(0, trainable=False)
    starter_learning_rate = 0.99
    learning_rate = tf.train.exponential_decay(starter_learning_rate,
                                               global_step,
                                               10000, 0.005)
    opt = tf.train.GradientDescentOptimizer(learning_rate)
    # Optimize on the variable zp
    train = opt.minimize(loss, var_list=zp, global_step=global_step)

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    for i in range(200): # Use more iterations (10000)
      # If we know the original latent vector, we can also compute
      # how far the recovered vector is from it
      _, loss_value, zp_val, eta = sess.run((train, loss, zp, learning_rate))
      z_loss = np.sqrt(np.sum(np.square(zp_val - start_zp))/len(zp_val[0]))
      print("%03d) eta=%03f, loss = %f, z_loss = %f" % (i, eta, loss_value, z_loss))
    # Save the recovered latent vector
    zp_val = sess.run(zp)
    np.save(folder + "zp_rec", zp_val)

    # Print out the corresponding image out of the recovered
    # latent vector
    imgs = sess.run(generator(zp))
    imgs = (imgs * 255).astype(np.uint8)
    Image.fromarray(imgs[0]).save(folder + "foo_rec.png")


